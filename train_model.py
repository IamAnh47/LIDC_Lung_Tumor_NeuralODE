import os
import yaml
import argparse
import torch
from torch.utils.data import DataLoader

# Import cÃ¡c module tá»« src
from src.models.full_model import NeuralODE3DReconstruction
from src.data.dataset_loader import LIDCDataset
from src.training.trainer import Trainer


def main():
    # --- 1. Cáº¥u hÃ¬nh tham sá»‘ (Arguments) ---
    parser = argparse.ArgumentParser(description="Huáº¥n luyá»‡n mÃ´ hÃ¬nh Neural ODE cho LIDC-IDRI")
    parser.add_argument("--config", type=str, default="configs/config.yaml", help="ÄÆ°á»ng dáº«n file cáº¥u hÃ¬nh")

    # ğŸ‘‡ THÃŠM THAM Sá» NÃ€Y Äá»‚ RESUME ğŸ‘‡
    parser.add_argument("--resume", type=str, default=None,
                        help="ÄÆ°á»ng dáº«n file .pth Ä‘á»ƒ train tiáº¿p (VD: experiments/.../last.pth)")

    args = parser.parse_args()

    # Load Config tá»« file YAML
    if not os.path.exists(args.config):
        raise FileNotFoundError(f"âŒ KhÃ´ng tÃ¬m tháº¥y file config táº¡i: {args.config}")

    with open(args.config, "r") as f:
        cfg = yaml.safe_load(f)

    print(f"ğŸš€ Báº®T Äáº¦U TRAINING: {cfg['project']['name']}")
    print("-" * 50)

    # --- 2. Thiáº¿t láº­p thiáº¿t bá»‹ (Device) ---
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ”Œ Thiáº¿t bá»‹ sá»­ dá»¥ng: {device} ({torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'})")

    # --- 3. Chuáº©n bá»‹ Dá»¯ liá»‡u (Data Loaders) ---
    processed_dir = os.path.abspath(cfg['paths']['processed_data'])

    train_dataset = LIDCDataset(processed_dir, split='train')

    # # --- ğŸ‘‡ THÃŠM ÄOáº N NÃ€Y Äá»‚ DEBUG ğŸ‘‡ ---
    # # Chá»‰ láº¥y Ä‘Ãºng 1 máº«u Ä‘áº§u tiÃªn Ä‘á»ƒ Ã©p model há»c thuá»™c lÃ²ng
    # from torch.utils.data import Subset
    # train_dataset = Subset(train_dataset, [10])
    # print("âš ï¸ ÄANG CHáº Y CHáº¾ Äá»˜ DEBUG: CHá»ˆ TRAIN 1 MáºªU!")
    # # ------------------------------------

    train_loader = DataLoader(
        train_dataset,
        batch_size=cfg['train']['batch_size'],
        shuffle=True,
        num_workers=2,
        pin_memory=True
    )

    val_dataset = LIDCDataset(processed_dir, split='val')
    val_loader = DataLoader(
        val_dataset,
        batch_size=cfg['train']['batch_size'],
        shuffle=False,
        num_workers=2,
        pin_memory=True
    )

    print(f"ğŸ“¦ Dá»¯ liá»‡u Train: {len(train_dataset)} máº«u")
    print(f"ğŸ“¦ Dá»¯ liá»‡u Val:   {len(val_dataset)} máº«u")

    # --- 4. Khá»Ÿi táº¡o MÃ´ hÃ¬nh (Model) ---
    #print("ğŸ§  Äang khá»Ÿi táº¡o mÃ´ hÃ¬nh Neural ODE + nnU-Net Encoder...")
    print("ğŸ§  Äang khá»Ÿi táº¡o mÃ´ hÃ¬nh Neural ODE + ResNet-3D-MedicalNet Encoder...")
    model = NeuralODE3DReconstruction(cfg)

    # --- 5. Khá»Ÿi táº¡o Trainer ---
    trainer = Trainer(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        config=cfg,
        device=device
    )

    # --- ğŸ‘‡ LOGIC LOAD CHECKPOINT Äá»‚ CHáº Y TIáº¾P ğŸ‘‡ ---
    start_epoch = 1
    best_val_loss = float('inf')

    if args.resume:
        if os.path.isfile(args.resume):
            print(f"ğŸ”„ Äang khÃ´i phá»¥c training tá»«: {args.resume}")
            checkpoint = torch.load(args.resume, map_location=device)

            # 1. Load trá»ng sá»‘ Model
            model.load_state_dict(checkpoint['state_dict'])

            # 2. Load tráº¡ng thÃ¡i Optimizer (Äá»ƒ giá»¯ Learning Rate Ä‘ang cháº¡y dá»Ÿ)
            if 'optimizer' in checkpoint:
                trainer.optimizer.load_state_dict(checkpoint['optimizer'])

            # 3. Cáº­p nháº­t Epoch báº¯t Ä‘áº§u
            start_epoch = checkpoint['epoch'] + 1
            print(f"âœ… KhÃ´i phá»¥c thÃ nh cÃ´ng! Sáº½ báº¯t Ä‘áº§u tá»« Epoch {start_epoch}")
        else:
            print(f"âš ï¸ KhÃ´ng tÃ¬m tháº¥y file checkpoint: {args.resume}. Sáº½ train tá»« Ä‘áº§u.")
    # -------------------------------------------------

    # --- 6. VÃ²ng láº·p Huáº¥n luyá»‡n (Training Loop) ---
    print("ğŸ”¥ Báº¯t Ä‘áº§u vÃ²ng láº·p huáº¥n luyá»‡n...")

    # Sá»­a range Ä‘á»ƒ cháº¡y tá»« start_epoch
    for epoch in range(start_epoch, cfg['train']['num_epochs'] + 1):
        print(f"\nEpoch {epoch}/{cfg['train']['num_epochs']}")

        # Train 1 epoch
        train_loss = trainer.train_epoch(epoch)
        print(f"   ğŸ“‰ Train Loss: {train_loss:.6f}")

        # Validate Ä‘á»‹nh ká»³
        if epoch % cfg['train'].get('val_every', 1) == 0:
            val_loss = trainer.validate(epoch)
            print(f"   ğŸ” Val Loss:   {val_loss:.6f}")

            # LÆ°u model tá»‘t nháº¥t (Checkpointing)
            if val_loss < best_val_loss:
                print(f"   â­ Loss giáº£m ({best_val_loss:.6f} -> {val_loss:.6f}). Äang lÆ°u Best Model...")
                best_val_loss = val_loss
                trainer.save_checkpoint(epoch, is_best=True)

        # LÆ°u model Ä‘á»‹nh ká»³ (Ä‘á»ƒ resume náº¿u sáº­p nguá»“n)
        if epoch % cfg['train']['save_every'] == 0:
            trainer.save_checkpoint(epoch, is_best=False)
            print(f"   ğŸ’¾ ÄÃ£ lÆ°u checkpoint Ä‘á»‹nh ká»³ táº¡i Epoch {epoch}")

    print("\nâœ… HUáº¤N LUYá»†N HOÃ€N Táº¤T!")
    # print(
    #     f"ğŸ‘‰ Model tá»‘t nháº¥t: {os.path.join(cfg['paths']['experiment_dir'], 'exp_01_nnunet', 'checkpoints', 'best_model.pth')}")
    print(
        f"ğŸ‘‰ Model tá»‘t nháº¥t: {os.path.join(cfg['paths']['experiment_dir'], 'exp_02_resnet', 'checkpoints', 'best_model.pth')}")

if __name__ == "__main__":
    main()