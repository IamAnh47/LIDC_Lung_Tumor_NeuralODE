import torch
import torch.nn as nn
from torchdiffeq import odeint_adjoint as odeint

# Import c·∫£ 2 lo·∫°i Encoder ƒë·ªÉ l·ª±a ch·ªçn
from .encoders import MedicalResNetEncoder, NNUnetEncoder
from .ode_func import ODEFunc
from .decoders import ImplicitDecoder


class NeuralODE3DReconstruction(nn.Module):
    def __init__(self, cfg):
        super().__init__()
        self.cfg = cfg

        # L·∫•y tham s·ªë t·ª´ config
        self.latent_dim = cfg['model']['latent_dim']
        hidden_dim = cfg['model']['hidden_dim']
        roi_depth = cfg['data']['roi_size'][0]  # S·ªë l√°t c·∫Øt theo tr·ª•c Z (th·ªùi gian)

        # --- 1. CH·ªåN ENCODER ---
        enc_name = cfg['model']['encoder_name'].lower()
        print(f"üß† ƒêang kh·ªüi t·∫°o Encoder: {enc_name.upper()}")

        if enc_name == "resnet":
            # D√πng ResNet-3D (MedicalNet Pre-trained) -> Nhanh, ·ªïn ƒë·ªãnh
            self.encoder = MedicalResNetEncoder(latent_dim=self.latent_dim, pretrained=True)
        elif "unet" in enc_name:
            # D√πng U-Net (Custom) -> Chi ti·∫øt cao, c·∫ßn train l√¢u
            self.encoder = NNUnetEncoder(latent_dim=self.latent_dim)
        else:
            raise ValueError(f"‚ùå Encoder '{enc_name}' kh√¥ng h·ª£p l·ªá. Ch·ªçn 'resnet' ho·∫∑c 'unet'.")

        # --- 2. KH·ªûI T·∫†O C√ÅC KH·ªêI KH√ÅC ---
        self.ode_func = ODEFunc(latent_dim=self.latent_dim, hidden_dim=hidden_dim)
        self.decoder = ImplicitDecoder(latent_dim=self.latent_dim, hidden_dim=hidden_dim)

        # --- 3. C·∫§U H√åNH ODE SOLVER ---
        self.ode_method = cfg['model'].get('ode', {}).get('method', 'dopri5')
        self.rtol = cfg['model'].get('ode', {}).get('rtol', 1e-3)
        self.atol = cfg['model'].get('ode', {}).get('atol', 1e-3)

        # T·∫°o l∆∞·ªõi th·ªùi gian c·ªë ƒë·ªãnh (Fixed Time Grid) ƒë·ªÉ gi·∫£i ODE 1 l·∫ßn d√πng cho c·∫£ batch
        # T·ª´ t=0 ƒë·∫øn t=1, s·ªë b∆∞·ªõc chia = ƒë·ªô s√¢u c·ªßa ·∫£nh ROI
        self.n_time_steps = roi_depth
        self.register_buffer('fixed_time_grid', torch.linspace(0, 1, self.n_time_steps))

    def manual_time_interpolation(self, z_grid, query_t):
        """
        H√†m n·ªôi suy tuy·∫øn t√≠nh th·ªß c√¥ng (Manual Linear Interpolation).
        Thay th·∫ø cho F.grid_sample ƒë·ªÉ tr√°nh l·ªói 'derivative not implemented' tr√™n GPU ƒë·ªùi m·ªõi.

        Args:
            z_grid: (Batch, Latent, T_steps) - K·∫øt qu·∫£ gi·∫£i ODE
            query_t: (Batch, N_points) - Th·ªùi gian t (tr·ª•c Z) c·ªßa c√°c ƒëi·ªÉm c·∫ßn query [0, 1]
        Returns:
            z_interp: (Batch, N_points, Latent)
        """
        batch_size, latent_dim, t_steps = z_grid.shape
        _, num_points = query_t.shape

        # 1. Quy ƒë·ªïi th·ªùi gian th·ª±c [0, 1] sang ch·ªâ s·ªë m·∫£ng [0, T-1]
        grid_idx = query_t * (t_steps - 1)
        # K·∫πp gi√° tr·ªã ƒë·ªÉ kh√¥ng b·ªã index out of bounds (tr√°nh l·ªói CUDA)
        grid_idx = torch.clamp(grid_idx, 0, t_steps - 1 - 1e-5)

        # 2. T√¨m ch·ªâ s·ªë S√†n (Floor) v√† Tr·∫ßn (Ceil)
        idx_floor = torch.floor(grid_idx).long()
        idx_ceil = idx_floor + 1

        # 3. T√≠nh tr·ªçng s·ªë n·ªôi suy (Kho·∫£ng c√°ch t·ª´ s√†n ƒë·∫øn ƒëi·ªÉm th·ª±c)
        # w = 0 -> L·∫•y gi√° tr·ªã t·∫°i Floor; w = 1 -> L·∫•y gi√° tr·ªã t·∫°i Ceil
        weight = grid_idx - idx_floor.float()  # (B, N)
        weight = weight.unsqueeze(1)  # (B, 1, N) ƒë·ªÉ broadcast

        # 4. L·∫•y gi√° tr·ªã Latent t·∫°i Floor v√† Ceil
        # M·ªü r·ªông index ƒë·ªÉ kh·ªõp v·ªõi chi·ªÅu Latent: (B, N) -> (B, Latent, N)
        idx_floor_expanded = idx_floor.unsqueeze(1).expand(-1, latent_dim, -1)
        idx_ceil_expanded = idx_ceil.unsqueeze(1).expand(-1, latent_dim, -1)

        # Gather: L·∫•y vector z t·∫°i c√°c ch·ªâ s·ªë th·ªùi gian t∆∞∆°ng ·ª©ng
        z_floor = torch.gather(z_grid, 2, idx_floor_expanded)
        z_ceil = torch.gather(z_grid, 2, idx_ceil_expanded)

        # 5. C√¥ng th·ª©c n·ªôi suy: (1-w)*a + w*b
        z_interp = (1 - weight) * z_floor + weight * z_ceil

        # ƒê·∫£o chi·ªÅu v·ªÅ (Batch, N, Latent) ƒë·ªÉ ƒë∆∞a v√†o Decoder
        return z_interp.permute(0, 2, 1)

    def forward(self, roi_image, query_coords):
        """
        Lu·ªìng x·ª≠ l√Ω ch√≠nh (Forward Pass).
        Input: ·∫¢nh CT + T·ªça ƒë·ªô ƒëi·ªÉm (x,y,z)
        Output: Gi√° tr·ªã SDF d·ª± ƒëo√°n
        """
        # --- B∆Ø·ªöC 1: ENCODE ---
        # Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng h√¨nh d·∫°ng c∆° b·∫£n t·ª´ ·∫£nh 3D
        z0 = self.encoder(roi_image)  # (Batch, Latent)

        # --- B∆Ø·ªöC 2: GI·∫¢I ODE (DYNAMICS) ---
        # T√≠nh to√°n s·ª± bi·∫øn ƒë·ªïi h√¨nh d·∫°ng d·ªçc theo tr·ª•c th·ªùi gian (Z)
        z_grid = odeint(
            self.ode_func,
            z0,
            self.fixed_time_grid,
            method=self.ode_method,
            rtol=self.rtol,
            atol=self.atol
        )
        # Output g·ªëc c·ªßa odeint l√† (T, B, L), ƒë·∫£o l·∫°i th√†nh (B, L, T) cho d·ªÖ x·ª≠ l√Ω
        z_grid = z_grid.permute(1, 2, 0)

        # --- B∆Ø·ªöC 3: N·ªòI SUY ƒê·∫∂C TR∆ØNG (INTERPOLATION) ---
        # L·∫•y t·ªça ƒë·ªô Z (th·ªùi gian) c·ªßa c√°c ƒëi·ªÉm c·∫ßn d·ª± ƒëo√°n
        query_z = query_coords[..., 0]  # (Batch, N)

        # N·ªôi suy ƒë·ªÉ l·∫•y vector ƒë·∫∑c tr∆∞ng ch√≠nh x√°c t·∫°i ƒë·ªô s√¢u Z ƒë√≥
        z_query = self.manual_time_interpolation(z_grid, query_z)  # (Batch, N, Latent)

        # --- B∆Ø·ªöC 4: SKIP CONNECTION (RESIDUAL LEARNING) ---
        # C·ªông vector g·ªëc z0 v√†o vector bi·∫øn ƒë·ªïi z_query.
        # Gi√∫p model kh√¥ng b·ªã qu√™n th√¥ng tin g·ªëc v√† h·ªôi t·ª• nhanh h∆°n.

        # M·ªü r·ªông z0: (B, Latent) -> (B, N, Latent)
        z0_expanded = z0.unsqueeze(1).expand(-1, z_query.shape[1], -1)

        # Ph√©p c·ªông th·∫ßn th√°nh
        z_combined = z_query + z0_expanded

        # --- B∆Ø·ªöC 5: DECODE (IMPLICIT FUNCTION) ---
        # L·∫•y t·ªça ƒë·ªô kh√¥ng gian 2D (Y, X)
        query_xy = query_coords[..., 1:]  # (Batch, N, 2)

        # ƒê∆∞a v√†o Decoder ƒë·ªÉ ra gi√° tr·ªã SDF
        pred_sdf = self.decoder(z_combined, query_xy)

        return pred_sdf