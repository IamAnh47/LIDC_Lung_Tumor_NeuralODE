# ğŸ« TÃ¡i táº¡o 3D Khá»‘i u Phá»•i LIDC-IDRI sá»­ dá»¥ng Neural ODE

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange)
![Status](https://img.shields.io/badge/Tráº¡ng_ThÃ¡i-NghiÃªn_Cá»©u-green)

## ğŸ“– Tá»•ng Quan (Overview)

Dá»± Ã¡n nÃ y triá»ƒn khai má»™t khung mÃ´ hÃ¬nh tiÃªn tiáº¿n (SOTA) **End-to-End Implicit Neural ODE** Ä‘á»ƒ tÃ¡i táº¡o lÆ°á»›i bá» máº·t 3D (Mesh) cháº¥t lÆ°á»£ng cao cá»§a cÃ¡c khá»‘i u phá»•i tá»« táº­p dá»¯ liá»‡u LIDC-IDRI.

KhÃ¡c vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p phÃ¢n Ä‘oáº¡n truyá»n thá»‘ng (voxel-based) hay biáº¿n dáº¡ng lÆ°á»›i máº«u (template deformation), mÃ´ hÃ¬nh nÃ y coi hÃ¬nh dáº¡ng khá»‘i u lÃ  má»™t quÃ¡ trÃ¬nh **biáº¿n Ä‘á»•i liÃªn tá»¥c dá»c theo trá»¥c Z (Ä‘á»™ sÃ¢u)**. Há»‡ thá»‘ng bao gá»“m:

* **Encoder:** Sá»­ dá»¥ng kiáº¿n trÃºc **3D nnU-Net** (thÆ° viá»‡n MONAI) Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng khÃ´ng gian tá»« cÃ¡c lÃ¡t cáº¯t CT thÆ°a thá»›t.
* **Latent Dynamics:** Sá»­ dá»¥ng bá»™ giáº£i **Neural ODE Solver** (`torchdiffeq`) Ä‘á»ƒ mÃ´ hÃ¬nh hÃ³a sá»± biáº¿n Ä‘á»•i hÃ¬nh dáº¡ng liÃªn tá»¥c vÃ  ná»™i suy cÃ¡c chi tiáº¿t giáº£i pháº«u bá»‹ thiáº¿u giá»¯a cÃ¡c lÃ¡t cáº¯t.
* **Decoder:** Má»™t máº¡ng **Implicit MLP** dá»± Ä‘oÃ¡n hÃ m khoáº£ng cÃ¡ch cÃ³ dáº¥u (Signed Distance Function - SDF) táº¡i báº¥t ká»³ tá»a Ä‘á»™ 3D nÃ o.

PhÆ°Æ¡ng phÃ¡p nÃ y giáº£i quyáº¿t hiá»‡u quáº£ váº¥n Ä‘á» **Ä‘á»™ phÃ¢n giáº£i khÃ´ng Ä‘á»“ng nháº¥t** (anisotropic resolution) thÆ°á»ng gáº·p trong áº£nh y táº¿.

---

## ğŸ“‚ Cáº¥u trÃºc Dá»± Ã¡n (Project Structure)
```bash
LIDC_Lung_Tumor_NeuralODE/
â”‚
â”œâ”€â”€ ğŸ“„ .pylidcrc                  # File cáº¥u hÃ¬nh Ä‘Æ°á»ng dáº«n cho thÆ° viá»‡n pylidc (Báº®T BUá»˜C)
â”œâ”€â”€ ğŸ“„ requirements.txt           # Danh sÃ¡ch cÃ¡c thÆ° viá»‡n cáº§n cÃ i Ä‘áº·t (PyTorch, MONAI, Pylidc...)
â”œâ”€â”€ ğŸ“„ README.md                  # TÃ i liá»‡u hÆ°á»›ng dáº«n sá»­ dá»¥ng dá»± Ã¡n
â”‚
â”œâ”€â”€ ğŸ“ configs/                   # Cáº¥u hÃ¬nh tham sá»‘ toÃ n cá»¥c (Hyperparameters)
â”‚   â””â”€â”€ config.yaml               # Chá»‰nh sá»­a learning rate, batch size, Ä‘Æ°á»ng dáº«n, tham sá»‘ model...
â”‚
â”œâ”€â”€ ğŸ“ data/                      # QUáº¢N LÃ Dá»® LIá»†U
â”‚   â”œâ”€â”€ ğŸ“‚ raw/                   # Dá»¯ liá»‡u thÃ´ (Immutable)
â”‚   â”‚   â””â”€â”€ LIDC-IDRI/            # ThÆ° má»¥c chá»©a cÃ¡c file DICOM giáº£i nÃ©n tá»« dataset gá»‘c
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“‚ processed/             # Dá»¯ liá»‡u sau khi tiá»n xá»­ lÃ½ (Sáºµn sÃ ng cho Training)
â”‚       â”œâ”€â”€ ğŸ“‚ rois/              # CÃ¡c khá»‘i 3D ROI (64x64x32) Ä‘Ã£ cáº¯t vÃ  chuáº©n hÃ³a (.npy)
â”‚       â”œâ”€â”€ ğŸ“‚ sdfs/              # Dá»¯ liá»‡u Ä‘iá»ƒm máº«u (x,y,z) vÃ  giÃ¡ trá»‹ SDF tÆ°Æ¡ng á»©ng (.npz)
â”‚       â”œâ”€â”€ ğŸ“‚ meshes_gt/         # Mesh Ground Truth (.obj) dÃ¹ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡
â”‚       â””â”€â”€ split_data.json       # File phÃ¢n chia táº­p dá»¯ liá»‡u: Train / Validation / Test
â”‚
â”œâ”€â”€ ğŸ“ src/                       # MÃƒ NGUá»’N CHÃNH (Source Code)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ data/                  # Module: Xá»­ lÃ½ dá»¯ liá»‡u (Data Pipeline)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ dicom_loader.py       # Wrapper cho pylidc Ä‘á»ƒ load scan vÃ  annotation
â”‚   â”‚   â”œâ”€â”€ preprocessing.py      # CÃ¡c hÃ m Resample, Crop ROI, Consensus Masking
â”‚   â”‚   â”œâ”€â”€ generation.py         # CÃ¡c hÃ m táº¡o Point Cloud vÃ  tÃ­nh toÃ¡n SDF
â”‚   â”‚   â””â”€â”€ dataset_loader.py     # Class CustomDataset phá»¥c vá»¥ PyTorch DataLoader
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ models/                # Module: Kiáº¿n trÃºc máº¡ng (Neural ODE Architecture)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ encoders.py           # 3D Encoder (Sá»­ dá»¥ng MONAI nnU-Net backbone)
â”‚   â”‚   â”œâ”€â”€ ode_func.py           # HÃ m vi phÃ¢n f(z,t) cho Neural ODE Solver
â”‚   â”‚   â”œâ”€â”€ decoders.py           # Implicit Decoder (MLP dá»± Ä‘oÃ¡n giÃ¡ trá»‹ SDF)
â”‚   â”‚   â””â”€â”€ full_model.py         # Class ghÃ©p ná»‘i toÃ n bá»™: Encoder -> ODE -> Decoder
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ training/              # Module: Huáº¥n luyá»‡n
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ losses.py             # CÃ¡c hÃ m Loss: SDF L1 Loss, Eikonal Loss
â”‚   â”‚   â””â”€â”€ trainer.py            # VÃ²ng láº·p huáº¥n luyá»‡n (Forward, Backward, Validation Loop)
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“‚ utils/                 # Module: Tiá»‡n Ã­ch bá»• trá»£
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ marching_cubes.py     # Thuáº­t toÃ¡n trÃ­ch xuáº¥t bá» máº·t 3D tá»« trÆ°á»ng SDF (Inference)
â”‚       â”œâ”€â”€ metrics.py            # TÃ­nh toÃ¡n chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡: Chamfer Distance, Hausdorff Distance
â”‚       â””â”€â”€ visualizer.py         # Váº½ biá»ƒu Ä‘á»“ Loss, hiá»ƒn thá»‹ lÃ¡t cáº¯t CT
â”‚
â”œâ”€â”€ ğŸ“ experiments/               # LOGS & CHECKPOINTS (LÆ°u káº¿t quáº£ cháº¡y)
â”‚   â””â”€â”€ ğŸ“‚ exp_01_unet/         # ThÃ­ nghiá»‡m chÃ­nh sá»­ dá»¥ng nnU-Net
â”‚       â”œâ”€â”€ ğŸ“‚ checkpoints/       # LÆ°u trá»ng sá»‘ mÃ´ hÃ¬nh tá»‘t nháº¥t (.pth)
â”‚       â”œâ”€â”€ ğŸ“‚ logs/              # File log Ä‘á»ƒ theo dÃµi trÃªn TensorBoard
â”‚       â””â”€â”€ ğŸ“‚ visuals/           # áº¢nh káº¿t quáº£ dá»± Ä‘oÃ¡n Ä‘Æ°á»£c lÆ°u tá»± Ä‘á»™ng khi train
â”‚
â”œâ”€â”€ ğŸ“ outputs/                   # Káº¾T QUáº¢ Äáº¦U RA (Final Results)
â”‚   â”œâ”€â”€ ğŸ“‚ predictions/           # CÃ¡c file .obj tÃ¡i táº¡o tá»« táº­p Test (DÃ¹ng Ä‘á»ƒ xem trÃªn Blender)
â”‚   â””â”€â”€ ğŸ“„ evaluation_report.csv  # Báº£ng bÃ¡o cÃ¡o Ä‘á»‹nh lÆ°á»£ng cÃ¡c chá»‰ sá»‘ (Metric Report)
â”‚
â”œâ”€â”€ ğŸ“ notebooks/                 # JUPYTER NOTEBOOKS (NhÃ¡p & Kiá»ƒm thá»­)
â”‚   â”œâ”€â”€ data_exploration.ipynb    # Kiá»ƒm tra, trá»±c quan hÃ³a dá»¯ liá»‡u pylidc
â”‚   â”œâ”€â”€ test_model.ipynb          # Cháº¡y thá»­ luá»“ng model (Debug kÃ­ch thÆ°á»›c tensor)
â”‚   â””â”€â”€ visualization.ipynb       # Váº½ hÃ¬nh áº£nh Ä‘áº¹p Ä‘á»ƒ Ä‘Æ°a vÃ o bÃ¡o cÃ¡o/paper
â”‚
â”œâ”€â”€ ğŸ prepare_data.py            # [BÆ°á»›c 1] Script cháº¡y tiá»n xá»­ lÃ½ dá»¯ liá»‡u
â”œâ”€â”€ ğŸ train_model.py             # [BÆ°á»›c 2] Script cháº¡y huáº¥n luyá»‡n mÃ´ hÃ¬nh
â””â”€â”€ ğŸ inference_eval.py          # [BÆ°á»›c 3] Script cháº¡y tÃ¡i táº¡o 3D vÃ  Ä‘Ã¡nh giÃ¡ káº¿t quáº£
```
---

# âš™ï¸ CÃ i Ä‘áº·t (Installation)
1. YÃªu cáº§u há»‡ thá»‘ng
Python 3.10+

GPU há»— trá»£ CUDA (Khuyáº¿n nghá»‹: 12GB+ VRAM Ä‘á»ƒ cháº¡y nnU-Net Encoder).

Dataset LIDC-IDRI: Táº£i vá» vÃ  giáº£i nÃ©n vÃ o thÆ° má»¥c data/raw/LIDC-IDRI/.

2. CÃ i Ä‘áº·t thÆ° viá»‡n 

Náº¿u dÃ¹ng colab, táº¡o local server trÃªn conda Ä‘á»ƒ cháº¡y colab
```bash
    conda create -n colab_local python=3.10 jupyter jupyterlab -y
    conda activate colab_local
    pip install jupyter_http_over_ws
    jupyter serverextension enable --py jupyter_http_over_ws
    jupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com' --port=8888 --no-browser --NotebookApp.port_retries=0
```
Náº¿u dÃ¹ng conda:
```bash
    # Táº¡o env tÃªn lidc-neuralode, dÃ¹ng python 3.9 hoáº·c 3.10 (thÆ°á»ng á»•n Ä‘á»‹nh nháº¥t cho NeuralODE cÅ©)
    conda create -n lidc-neuralode python=3.10 -y
    conda activate lidc-neuralode
    
    # Install pytorch Ä‘Ãºng phiÃªn báº£n trÆ°á»›c (theo cuda cá»§a mÃ¡y)
    # VÃ­ dá»¥ mÃ¡y cÃ³ CUDA 11.8
    conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia
    
    # Sau Ä‘Ã³ má»›i install cÃ¡i requirements.txt
    pip install -r requirements.txt
```
Náº¿u dÃ¹ng cmd nhÆ° bÃ¬nh thÆ°á»ng thÃ¬ dÃ¹ng venv, cÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t
```bash
    python -m venv venv
  # 2. KÃ­ch hoáº¡t env
    .\venv\Scripts\Activate
    
    # 3. Upgrade pip trong env
    python -m pip install --upgrade pip
    
    # 4. Install requirements
    pip install -r requirements.txt
```
Náº¿u khÃ´ng thÃ­ch há»£p GPU thÃ¬: 
```bash
    pip install --pre torch torchvision --index-url https://download.pytorch.org/whl/nightly/cu128
    # Cháº¡y test xem nÃ³ á»•n khÃ´ng
    python -c "import torch; print(torch.rand(2,2).cuda())"
```
3. Cáº¥u hÃ¬nh
Dá»± Ã¡n sá»­ dá»¥ng cÆ¡ cháº¿ "God Mode Loader" Ä‘á»ƒ tá»± Ä‘á»™ng tÃ¬m Ä‘Æ°á»ng dáº«n dá»¯ liá»‡u. Tuy nhiÃªn, hÃ£y kiá»ƒm tra file configs/config.yaml Ä‘á»ƒ Ä‘áº£m báº£o cÃ¡c tham sá»‘ roi_size (kÃ­ch thÆ°á»›c cáº¯t) vÃ  sdf_samples (sá»‘ Ä‘iá»ƒm máº«u) phÃ¹ há»£p vá»›i pháº§n cá»©ng.

# ğŸš€ Quy trÃ¬nh Thá»±c hiá»‡n (Workflow)

## BÆ°á»›c 1: Tiá»n xá»­ lÃ½ dá»¯ liá»‡u (Preprocessing)
1. Náº¡p dá»¯ liá»‡u & Gá»™p nhÃ£n (Consensus)
- Váº¥n Ä‘á»: Trong bá»™ dá»¯ liá»‡u LIDC-IDRI, má»—i nodule Ä‘Æ°á»£c Ä‘Ã¡nh dáº¥u bá»Ÿi tá»‘i Ä‘a 4 bÃ¡c sÄ© cháº©n Ä‘oÃ¡n hÃ¬nh áº£nh. Má»—i ngÆ°á»i váº½ má»™t Ä‘Æ°á»ng viá»n khÃ¡c nhau.
- ChÃºng ta cáº§n táº¡o ra má»™t Ground Truth Ä‘á»ƒ mÃ¡y há»c.
- Ká»¹ thuáº­t: Majority Voting - bá» phiáº¿u Ä‘a sá»‘ - 50%.
- CÃ¡ch thá»±c hiá»‡n:Chá»“ng 4 mask cá»§a 4 bÃ¡c sÄ© lÃªn nhau. Má»™t voxel chá»‰ Ä‘Æ°á»£c coi lÃ  "Khá»‘i u" náº¿u cÃ³ Ã­t nháº¥t 2 trÃªn 4 bÃ¡c sÄ© Ä‘á»“ng Ã½.Náº¿u chá»‰ cÃ³ 1 ngÆ°á»i khoanh vÃ¹ng Ä‘Ã³ -> Coi lÃ  nhiá»…u, bá» qua.
- => CÃ¡ch nÃ y giÃºp loáº¡i bá» cÃ¡c sai sÃ³t cÃ¡ nhÃ¢n cá»§a tá»«ng bÃ¡c sÄ© vÃ  táº¡o ra má»™t mask cÃ³ Ä‘á»™ tin cáº­y cao nháº¥t.
2. Äá»“ng nháº¥t Ä‘á»™ phÃ¢n giáº£
- Váº¥n Ä‘á»: áº¢nh CT lÃ  táº­p há»£p cÃ¡c lÃ¡t cáº¯t 2D xáº¿p chá»“ng lÃªn nhau.
- Äá»™ phÃ¢n giáº£i trÃªn máº·t lÃ¡t cáº¯t trá»¥c X, Y ráº¥t nÃ©t: thÆ°á»ng lÃ  0.5mm - 0.7mm.
- NhÆ°ng khoáº£ng cÃ¡ch giá»¯a cÃ¡c lÃ¡t cáº¯t trá»¥c Z thÆ°á»ng ráº¥t dÃ y: 2.0mm - 3.0mm.
- Náº¿u Ä‘á»ƒ nguyÃªn, khá»‘i u hÃ¬nh cáº§u sáº½ bá»‹ mÃ¡y tÃ­nh nhÃ¬n thÃ nh hÃ¬nh dáº¹t vÃ¬ trá»¥c Z bá»‹ nÃ©n.
- => ÄÆ°a táº¥t cáº£ vá» cÃ¹ng má»™t Ä‘á»™ phÃ¢n giáº£i chuáº©n $1mm \times 1mm \times 1mm$.
- Ká»¹ thuáº­t: Interpolation.
+ Vá»›i áº£nh CT: DÃ¹ng Spline Interpolation báº­c 1  Ä‘á»ƒ giá»¯ Ä‘á»™ mÆ°á»£t.
+ Vá»›i Mask: DÃ¹ng Nearest Neighbor (báº­c 0) Ä‘á»ƒ Ä‘áº£m báº£o mask váº«n chá»‰ lÃ  0 vÃ  1, khÃ´ng bá»‹ ra sá»‘ tháº­p phÃ¢n má» nhÃ²e.
3. Intensity Normalization
- MÃ¡y chá»¥p CT Ä‘o Ä‘á»™ Ä‘áº­m Ä‘áº·c cá»§a váº­t cháº¥t báº±ng Ä‘Æ¡n vá»‹ Hounsfield Unit (HU).
+ KhÃ­: -1000 HU
+ NÆ°á»›c: 0 HU
+ XÆ°Æ¡ng: +1000 HU
+ GiÃ¡ trá»‹ nÃ y quÃ¡ lá»›n Ä‘á»ƒ Ä‘Æ°a vÃ o Máº¡ng NÆ¡-ron (thÆ°á»ng thÃ­ch sá»‘ tá»« 0 Ä‘áº¿n 1).
- BÆ°á»›c 1 (Clipping): Chá»‰ quan tÃ¢m Ä‘áº¿n Lung Window. Ta cáº¯t bá» má»i giÃ¡ trá»‹ náº±m ngoÃ i khoáº£ng $[-1000, 400]$.
+ DÆ°á»›i -1000 (khÃ­ ngoÃ i cÆ¡ thá»ƒ): GÃ¡n thÃ nh -1000.
+ TrÃªn 400 (xÆ°Æ¡ng): GÃ¡n thÃ nh 400.
- BÆ°á»›c 2 (Scaling): Co giÃ£n khoáº£ng $[-1000, 400]$ vá» Ä‘oáº¡n $[0, 1]$.
4. ROI Cropping
- Phá»•i ráº¥t to ($512 \times 512 \times \text{Depth}$), nhÆ°ng khá»‘i u chá»‰ bÃ© táº¹o (khoáº£ng 10-30mm). Náº¿u Ä‘Æ°a cáº£ phá»•i vÃ o, mÃ´ hÃ¬nh sáº½ bá»‹ loÃ£ng thÃ´ng tin.
Giá»:
+ TÃ¬m tÃ¢m cá»§a khá»‘i u (tá»« bÆ°á»›c Consensus).
+ Cáº¯t má»™t khá»‘i há»™p kÃ­ch thÆ°á»›c cá»‘ Ä‘á»‹nh $64 \times 64 \times 32$ bao quanh tÃ¢m Ä‘Ã³.
+ Padding: Náº¿u khá»‘i u náº±m sÃ¡t rÃ¬a phá»•i, ta bÃ¹ thÃªm cÃ¡c pixel cÃ³ giÃ¡ trá»‹ 0 (mÃ u Ä‘en) Ä‘á»ƒ Ä‘áº£m báº£o kÃ­ch thÆ°á»›c Ä‘áº§u vÃ o luÃ´n cá»‘ Ä‘á»‹nh.
5. SDF Generation
DÃ¹ng cho mÃ´ hÃ¬nh Implicit Neural ODE, náº¿u dÃ¹ng mÃ´ hÃ¬nh khÃ¡c cÃ³ thá»ƒ tham kháº£o. MÃ´ hÃ¬nh nÃ y khÃ´ng há»c tá»« áº£nh Mask, mÃ  há»c tá»« cÃ¡c Äiá»ƒm trong khÃ´ng gian.
- Input: Mask 3D cá»§a khá»‘i u.
- BÆ°á»›c 1: DÃ¹ng thuáº­t toÃ¡n Marching Cubes Ä‘á»ƒ chuyá»ƒn Mask voxel thÃ nh Mesh.
- BÆ°á»›c 2: Sinh ra 10.000 Ä‘iá»ƒm $(x, y, z)$.
+ 80% Ä‘iá»ƒm: Náº±m ngay trÃªn bá» máº·t hoáº·c cá»±c sÃ¡t bá» máº·t khá»‘i u Ä‘á»ƒ mÃ´ hÃ¬nh há»c ká»¹ biÃªn dáº¡ng.
+ 20% Ä‘iá»ƒm: Náº±m ngáº«u nhiÃªn trong há»™p ROI Ä‘á»ƒ mÃ´ hÃ¬nh biáº¿t Ä‘Ã¢u lÃ  ná»n/background.
- BÆ°á»›c 3 (TÃ­nh SDF): Vá»›i má»—i Ä‘iá»ƒm, tÃ­nh khoáº£ng cÃ¡ch ngáº¯n nháº¥t tá»« nÃ³ Ä‘áº¿n bá» máº·t Mesh.
+ Äiá»ƒm bÃªn trong u: GiÃ¡ trá»‹ Ã‚m (-).
+ Äiá»ƒm bÃªn ngoÃ i u: GiÃ¡ trá»‹ DÆ°Æ¡ng (+).
+ Scale: Chia giÃ¡ trá»‹ nÃ y cho 20.0 Ä‘á»ƒ máº¡ng dá»… há»c.

```bash
    rmdir /s /q data\processed # Neu duoc tao tu truoc
    python prepare_data.py
```
Káº¿t quáº£: CÃ¡c file .npy vÃ  .npz Ä‘Æ°á»£c táº¡o trong data/processed/.

## BÆ°á»›c 2: Huáº¥n luyá»‡n MÃ´ hÃ¬nh (Training)
- HÃ m loss:
Tá»•ng hÃ m Loss $\mathcal{L}$ lÃ  sá»± káº¿t há»£p giá»¯a SDF Reconstruction Loss Ä‘á»ƒ táº¡o hÃ¬nh dÃ¡ng vÃ  Eikonal Loss Ä‘á»ƒ lÃ m má»‹n bá» máº·t:

![img.png](img_loss_func/Loss_final.png)

Trong Ä‘Ã³ há»‡ sá»‘ $\lambda = 0.005$

1. Weighted SDF L1 Loss
ÄÃ¢y lÃ  thÃ nh pháº§n chÃ­nh giÃºp mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c hÃ¬nh dáº¡ng khá»‘i u. Sá»­ dá»¥ng L1 Loss cÃ³ trá»ng sá»‘ vÃ  káº¹p giÃ¡ trá»‹.

![img.png](img_loss_func/L1.png)

Giáº£i thÃ­ch:
- $N$: Sá»‘ lÆ°á»£ng Ä‘iá»ƒm máº«u (batch size $\times$ sá»‘ Ä‘iá»ƒm).
- $x_i$: Tá»a Ä‘á»™ Ä‘iá»ƒm 3D $(z, y, x)$.
- $s_{\text{pred}}(x_i)$: GiÃ¡ trá»‹ SDF do mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n.
- $s_{\text{gt}}(x_i)$: GiÃ¡ trá»‹ SDF thá»±c táº¿ (Ground Truth).
- HÃ m $\text{clamp}(v, -\epsilon, \epsilon)$: Káº¹p giÃ¡ trá»‹ Ground Truth trong khoáº£ng nhá» ($[-0.5, 0.5]$) Ä‘á»ƒ mÃ´ hÃ¬nh táº­p trung há»c ká»¹ vÃ¹ng bá» máº·t, bá» qua sai sá»‘ á»Ÿ vÃ¹ng xa.
- $w_i$ (Trá»ng sá»‘): Pháº¡t náº·ng náº¿u Ä‘oÃ¡n sai vÃ¹ng bÃªn trong khá»‘i u.

$$w_i = \begin{cases} 15.0 & \text{náº¿u } s_{\text{gt}}(x_i) < 0 \text{ (BÃªn trong u)};
\\ 1.0 & \text{náº¿u } s_{\text{gt}}(x_i) \ge 0 \text{ (BÃªn ngoÃ i u)} \end{cases}$$

2. Eikonal Regularization
ÄÃ¢y lÃ  thÃ nh pháº§n phá»¥ trá»£ giÃºp bá» máº·t trÆ¡n mÆ°á»£t vÃ  Ä‘Ãºng tÃ­nh cháº¥t váº­t lÃ½. Theo Ä‘á»‹nh nghÄ©a toÃ¡n há»c, Ä‘á»™ lá»›n gradient cá»§a má»™t hÃ m khoáº£ng cÃ¡ch (SDF) táº¡i báº¥t ká»³ Ä‘Ã¢u pháº£i luÃ´n báº±ng 1.

![img.png](img_loss_func/Eikonal.png)

Giáº£i thÃ­ch:
- $\nabla_{x} s_{\text{pred}}$: Äáº¡o hÃ m (Gradient) cá»§a giÃ¡ trá»‹ dá»± Ä‘oÃ¡n theo tá»a Ä‘á»™ khÃ´ng gian $(x, y, z)$.
- NÃ³ Ã©p mÃ´ hÃ¬nh: Äá»«ng thay Ä‘á»•i giÃ¡ trá»‹ quÃ¡ gáº¯t, cÅ©ng Ä‘á»«ng thay Ä‘á»•i quÃ¡ cháº­m, hÃ£y thay Ä‘á»•i Ä‘á»u Ä‘áº·n vá»›i tá»‘c Ä‘á»™ báº±ng 1.


Huáº¥n luyá»‡n máº¡ng Neural ODE. Script há»— trá»£ Mixed-precision training (AMP) Ä‘á»ƒ tÄƒng tá»‘c Ä‘á»™ vÃ  TensorBoard Ä‘á»ƒ theo dÃµi Loss.

```bash
  rmdir /s /q experiments\exp_02_resnet
  python train_model.py --config configs/config.yaml
  python train_model.py --config configs/config.yaml --resume experiments/exp_01_unet/checkpoints/last.pth
  python train_model.py --config configs/config.yaml --resume experiments/exp_02_resnet/checkpoints/last.pth
```
Káº¿t quáº£: File trá»ng sá»‘ model tá»‘t nháº¥t Ä‘Æ°á»£c lÆ°u táº¡i experiments/exp_01_unet/checkpoints/.

## BÆ°á»›c 3: Suy luáº­n & ÄÃ¡nh giÃ¡ (Inference & Evaluation)
TÃ¡i táº¡o Mesh 3D tá»« táº­p dá»¯ liá»‡u kiá»ƒm tra (Test set) vÃ  tÃ­nh toÃ¡n cÃ¡c chá»‰ sá»‘ sai sá»‘ hÃ¬nh há»c (Chamfer Distance, Hausdorff Distance).

```bash
# Cháº¡y vá»›i checkpoint tá»‘t nháº¥t
python inference_eval.py --checkpoint experiments/exp_01_unet/checkpoints/best_model.pth
python inference_eval.py --checkpoint experiments/exp_02_resnet/checkpoints/best_model.pth
```
# ğŸ“Š Káº¿t quáº£ & Trá»±c quan hÃ³a
Theo dÃµi quÃ¡ trÃ¬nh Train
Má»Ÿ TensorBoard Ä‘á»ƒ xem biá»ƒu Ä‘á»“ Loss vÃ  Eikonal regularization theo thá»i gian thá»±c:
```bash
tensorboard --logdir experiments/exp_01_unet/logs
tensorboard --logdir experiments/exp_02_resnet/logs
```
# Xem mÃ´ hÃ¬nh 3D
CÃ¡c file Ä‘áº§u ra .obj Ä‘Ã£ Ä‘Æ°á»£c cÄƒn giá»¯a (centered) vÃ  Ä‘Ãºng tá»· lá»‡. Äá»ƒ xem:

Má»Ÿ pháº§n má»m Blender.

Import file Wavefront (.obj).

TÃ¡c giáº£: Tuáº¥n Anh, HCMUT